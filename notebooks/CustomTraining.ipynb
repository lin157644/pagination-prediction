{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from urllib.parse import urlparse, urlsplit, parse_qs, parse_qsl\n",
    "\n",
    "import numpy as np\n",
    "import parsel\n",
    "from sklearn_crfsuite.metrics import flat_classification_report, sequence_accuracy_score\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from autopager.storage import Storage\n",
    "from autopager.htmlutils import (get_link_text, get_text_around_selector_list,\n",
    "                                 get_link_href, get_selector_root)\n",
    "from autopager.utils import (\n",
    "    get_domain, normalize_whitespaces, normalize, ngrams, tokenize, ngrams_wb, replace_digits\n",
    ")\n",
    "from autopager.model import _num_tokens_feature, _elem_attr\n",
    "from autopager import AUTOPAGER_LIMITS\n",
    "from autopager.parserutils import (TagParser, MyHTMLParser, draw_scaled_page, position_check, compare_tag, get_first_tag)\n",
    "parser = MyHTMLParser()\n",
    "tagParser = TagParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import random\n",
    "tf.random.set_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_GPU = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus)!=0:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[USED_GPU], 'GPU')\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs visible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "urls = [rec['Page URL'] for rec in storage.iter_records(language='en',contain_button = True, file_type='T')]\n",
    "X_raw, y, page_positions = storage.get_Xy(language='en',contain_button = True,  contain_position=True,file_type='T', scaled_page='normal')\n",
    "print(\"pages: {}  domains: {}\".format(len(urls), len({get_domain(url) for url in urls})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_page_seq = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice data into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_empty(x, y):\n",
    "    res_x = [page for page in x if len(x)!= 0]\n",
    "    res_y = [page for page in y if len(y)!= 0]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_x, chunks_y, chunk_positions = X_raw, y, page_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_x, chunks_y = filter_empty(chunks_x, chunks_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Laser embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LaserSentenceModel import LaserSentenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = LaserSentenceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser.getSentenceVector('hello').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToMultiVector(text):\n",
    "    ngram_next = _as_list(ngrams_wb(replace_digits(text), 2, 5),AUTOPAGER_LIMITS.max_text_features)\n",
    "    return np.average(laser.getSentenceVector(ngram_next), axis = 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cos_sim(laser.getSentenceVector('下一頁'), laser.getSentenceVector('next page'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# XXX: these functions should be copy-pasted from autopager/model.py\n",
    "\n",
    "def _as_list(generator, limit=None):\n",
    "    \"\"\"\n",
    "    >>> _as_list(ngrams_wb(\"text\", 2, 2), 0)\n",
    "    []\n",
    "    >>> _as_list(ngrams_wb(\"text\", 2, 2), 2)\n",
    "    ['te', 'ex']\n",
    "    >>> _as_list(ngrams_wb(\"text\", 2, 2))\n",
    "    ['te', 'ex', 'xt']\n",
    "    \"\"\"\n",
    "    return list(generator if limit is None else islice(generator, 0, limit))\n",
    "\n",
    "def feat_to_tokens(feat, tokenizer):\n",
    "    if type(feat) == type([]):\n",
    "        feat = ' '.join(feat)\n",
    "    tokens = tokenizer.tokenize(feat)\n",
    "    return tokens\n",
    "\n",
    "def num_token_feature_to_class(number):\n",
    "    if number == '=0':\n",
    "        return [1, 0, 0, 0]\n",
    "    elif number == '=1':\n",
    "        return [0, 1, 0, 0]\n",
    "    elif number == '=2':\n",
    "        return [0, 0, 1, 0]\n",
    "    else:\n",
    "        return [0, 0, 0, 1]\n",
    "\n",
    "def link_to_features(link):\n",
    "    text = normalize(get_link_text(link))\n",
    "    href = get_link_href(link)\n",
    "    if href is None:\n",
    "        href = \"\"\n",
    "    p = urlsplit(href)\n",
    "    parent = link.xpath('..').extract()\n",
    "    parent = get_first_tag(parser, parent[0])\n",
    "    query_parsed = parse_qsl(p.query) #parse query string from path\n",
    "    query_param_names = [k.lower() for k, v in query_parsed]\n",
    "    query_param_names_ngrams = _as_list(ngrams_wb(\n",
    "        \" \".join([normalize(name) for name in query_param_names]), 3, 5, True\n",
    "    ))\n",
    "\n",
    "    # Classes of link itself and all its children.\n",
    "    # It is common to have e.g. span elements with fontawesome\n",
    "    # arrow icon classes inside <a> links.\n",
    "    self_and_children_classes = ' '.join(link.xpath(\".//@class\").extract())\n",
    "    parent_classes = ' '.join(link.xpath('../@class').extract())\n",
    "    css_classes = normalize(parent_classes + ' ' + self_and_children_classes)\n",
    "    \n",
    "    token_feature = {\n",
    "        'text-exact': replace_digits(text.strip()[:100].strip()),\n",
    "#         'query': query_param_names,\n",
    "        'query': query_param_names_ngrams,\n",
    "        'parent-tag': parent,\n",
    "#         'class': css_classes.split()[:AUTOPAGER_LIMITS.max_css_features],\n",
    "        'class':_as_list(ngrams_wb(css_classes, 4, 5),\n",
    "                          AUTOPAGER_LIMITS.max_css_features),\n",
    "        'text': _as_list(ngrams_wb(replace_digits(text), 2, 5),\n",
    "                         AUTOPAGER_LIMITS.max_text_features),\n",
    "    }\n",
    "    tag_feature = {\n",
    "        'isdigit': 1 if text.isdigit() is True else 0,\n",
    "        'isalpha': 1 if text.isalpha() is True else 0,\n",
    "        'has-href': 0 if href is \"\" else 1,\n",
    "        'path-has-page': 1 if 'page' in p.path.lower() else 0,\n",
    "        'path-has-pageXX': 1 if re.search(r'[/-](?:p|page\\w?)/?\\d+', p.path.lower()) is not None else 0,\n",
    "        'path-has-number': 1 if any(part.isdigit() for part in p.path.split('/')) else 0,\n",
    "        'href-has-year': 1 if re.search('20\\d\\d', href) is not None else 0,\n",
    "        'class-has-disabled': 1 if 'disabled' in css_classes else 0,\n",
    "#         'num-tokens': num_token_feature_to_class(_num_tokens_feature(text)),\n",
    "    }\n",
    "    non_token_feature = []\n",
    "    for k,v in tag_feature.items():\n",
    "        if type(v) == type([]):\n",
    "            non_token_feature.extend(v)\n",
    "        else:\n",
    "            non_token_feature.append(v)\n",
    "\n",
    "    return [token_feature, non_token_feature]\n",
    "\n",
    "\n",
    "def page_to_features(xseq):\n",
    "    feat_list = [link_to_features(a) for a in xseq]\n",
    "    around = get_text_around_selector_list(xseq, max_length=15)\n",
    "#     print(len(feat_list))\n",
    "    for feat, (before, after) in zip(feat_list, around):\n",
    "        feat[0]['text-full'] = normalize(before) + ',' + feat[0]['text-exact'] + ',' + normalize(after)\n",
    "    \n",
    "    return feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_tag_features_from_chunks(chunks):\n",
    "    token_features = []\n",
    "    tag_features = []\n",
    "    for idx, page in enumerate(chunks):\n",
    "        try:\n",
    "            feat_list = page_to_features(page)\n",
    "            token_features.append([node[0] for node in feat_list])\n",
    "            tag_features.append(np.array([node[1] for node in feat_list]))\n",
    "        except:\n",
    "            raise Exception(f\"Error occured on {idx}\")\n",
    "    return token_features, tag_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_vector(word_list, word_vector_method = None):\n",
    "    if word_vector_method is None:\n",
    "        print(\"Need to specified a method.\")\n",
    "        return\n",
    "    elif word_vector_method == 'FastText':\n",
    "        if type(word_list) == type([]):\n",
    "            if len(word_list) == 0:\n",
    "                return np.zeros(ft.getModel().get_dimension())\n",
    "            else:\n",
    "                vectors_array = []\n",
    "                for word in word_list:\n",
    "                    vector = ft.getWordVector(word)\n",
    "                    vectors_array.append(vector)\n",
    "                mean_vector = np.mean(vectors_array, axis = 0)\n",
    "                return mean_vector\n",
    "        else:\n",
    "            return ft.getWordVector(word_list)\n",
    "    elif word_vector_method == 'Laser':\n",
    "        return laser.getSentenceVector(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages_to_word_vector(ft, token_features):\n",
    "    pages_vector = []\n",
    "    for page in token_features:\n",
    "        page_vectors = []\n",
    "        for node in page:\n",
    "            classes = word_to_vector(ft, node['class'])\n",
    "            query = word_to_vector(ft, node['query'])\n",
    "            p_tag = word_to_vector(ft, node['parent-tag'])\n",
    "            full_vector = np.concatenate([classes, query, p_tag], axis = 0)\n",
    "            page_vectors.append(full_vector)\n",
    "        pages_vector.append(np.array(page_vectors))\n",
    "    return pages_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_features, tag_features = get_token_tag_features_from_chunks(chunks_x)\n",
    "# train_tag_feature_token_list = extract_tokens_from_token_features(token_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_feature_list = list(token_features[0][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pages_to_word_vector_from_keylist(word_vector_method, token_features, word_to_vec_list = token_feature_list):\n",
    "    print(f\"Transform key {word_to_vec_list} to word_vector ... \")\n",
    "    pages_vector = []\n",
    "    p = IntProgress(max=len(token_features))\n",
    "    p.description = '(Init)'\n",
    "    p.value = 0\n",
    "    display(p)\n",
    "    for idx, page in enumerate(token_features):\n",
    "        p.description = f\"Task: {idx+1}\"\n",
    "        p.value = idx+1\n",
    "        page_vectors = []\n",
    "        for node in page:\n",
    "            full_vector_list = []\n",
    "            for k,v in node.items():\n",
    "                if k in word_to_vec_list:\n",
    "                    full_vector_list.append(word_to_vector(v, word_vector_method))\n",
    "            full_vector = np.concatenate(full_vector_list, axis=0)\n",
    "            page_vectors.append(full_vector)\n",
    "        pages_vector.append(np.array(page_vectors))\n",
    "    p.description = '(Done)'\n",
    "    return pages_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare class and query features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_set = set()\n",
    "query_set = set()\n",
    "class_counter = dict()\n",
    "query_counter = dict()\n",
    "for page in token_features:\n",
    "    for node in page:\n",
    "        for class_name in node['class']:\n",
    "            if class_name not in class_set:\n",
    "                if str(len(class_name)) not in class_counter:\n",
    "                    class_counter[str(len(class_name))] = 1\n",
    "                else:\n",
    "                    if class_name not in class_set:\n",
    "                        class_counter[str(len(class_name))] += 1\n",
    "                class_set.add(class_name)\n",
    "        for query_name in node['query']:\n",
    "            if query_name not in query_set:\n",
    "                if str(len(query_name)) not in query_counter:\n",
    "                    query_counter[str(len(query_name))] = 1\n",
    "                else:\n",
    "                    query_counter[str(len(query_name))] += 1\n",
    "                query_set.add(query_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare top 30 parent tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_parent_tags = {}\n",
    "for page in token_features:\n",
    "    for node in page:\n",
    "        p_tag = node['parent-tag']\n",
    "        if p_tag not in top_parent_tags:\n",
    "            top_parent_tags[p_tag] = 1\n",
    "        else:\n",
    "            top_parent_tags[p_tag] += 1\n",
    "sorted_parent_tags = sorted(top_parent_tags.items(),key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map_for_ptag = sorted_parent_tags[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_representation_with_map(tag, data_map = data_map_for_ptag):\n",
    "    rt_vec = [0] * len(data_map)\n",
    "    for idx, map_tag in enumerate(data_map):\n",
    "        if tag == map_tag[0]:\n",
    "            rt_vec[idx] = 1\n",
    "            break\n",
    "    return rt_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ptags_vector(token_features):\n",
    "    pages_ptag = []\n",
    "    for page in token_features:\n",
    "        ptag_page = []\n",
    "        for node in page:\n",
    "            p_tag = node['parent-tag']\n",
    "            ptag_page.append(sparse_representation_with_map(p_tag))\n",
    "        pages_ptag.append(np.array(ptag_page))\n",
    "    return pages_ptag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get parent tag vector\n",
    "ptags_vector = get_ptags_vector(token_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class, Query tokens by tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagTokenizer:\n",
    "    def __init__(self, myDict = None):\n",
    "        rt_dict = {}\n",
    "        rt_dict['[PAD]'] = 0\n",
    "        rt_dict['[UNK]'] = 1\n",
    "        i = 2\n",
    "        if myDict is not None:\n",
    "            for k,v in myDict.items():\n",
    "                rt_dict[k] = i\n",
    "                i+=1\n",
    "        self.map = rt_dict\n",
    "        \n",
    "    def tokenize(self, word):\n",
    "        if type(word) == type([]):\n",
    "            token_list = []\n",
    "            for _word in word:\n",
    "                if _word not in self.map:\n",
    "                    token_list.append(self.map['[UNK]'])\n",
    "                else:\n",
    "                    token_list.append(self.map[_word])\n",
    "            return token_list\n",
    "        else:\n",
    "            if word not in self.map:\n",
    "                return self.map['[UNK]']\n",
    "            else:\n",
    "                return self.map[word]\n",
    "    def get_size(self):\n",
    "        return len(self.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_thousand_class = {}\n",
    "top_thousand_query = {}\n",
    "for page in token_features:\n",
    "    for node in page:\n",
    "        for _class in node['class']:\n",
    "            if _class in top_thousand_class:\n",
    "                top_thousand_class[_class]+=1\n",
    "            else:\n",
    "                top_thousand_class[_class]=1\n",
    "        for _query in node['query']:\n",
    "            if _query in top_thousand_query:\n",
    "                top_thousand_query[_query]+=1\n",
    "            else:\n",
    "                top_thousand_query[_query]=1\n",
    "\n",
    "class_tokenizer = TagTokenizer(top_thousand_class)\n",
    "query_tokenizer = TagTokenizer(top_thousand_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get pre-trained sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ft to encode all token_features\n",
    "# ft_full_tokens_emb = pages_to_word_vector_from_keylist('Laser', token_features, ['text-exact'])\n",
    "ft_full_tokens_emb = pages_to_word_vector_from_keylist('Laser', token_features, ['text-full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding/train/LaserEmb_full.npy', ft_full_tokens_emb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ft_full_tokens_emb = np.load('embedding/train/LaserEmb.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ft_full_tokens_emb = first_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_info_list = tag_features #features which only have tag true/false information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding to fixed size and prepare for training inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_ids(page_tokens, max_len):\n",
    "    pages_class = []\n",
    "    pages_query = []\n",
    "#     print(len(page_tokens))\n",
    "    for page in page_tokens:\n",
    "        class_page = []\n",
    "        query_page = []\n",
    "        for node in page:\n",
    "            #class\n",
    "            class_ids = class_tokenizer.tokenize(node['class'])\n",
    "            class_ids = class_ids + [0] * (max_len-len(class_ids))\n",
    "            class_page.append(class_ids[:max_len])\n",
    "            #query\n",
    "            query_ids = query_tokenizer.tokenize(node['query'])\n",
    "            query_ids = query_ids + [0] * (max_len-len(query_ids))\n",
    "            query_page.append(query_ids[:max_len])\n",
    "        pages_class.append(np.array(class_page))\n",
    "        pages_query.append(np.array(query_page))\n",
    "    return pages_class, pages_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_class, pages_query = prepare_input_ids(token_features, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attr_x = ft_full_tokens_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ptag = ptags_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_x = tag_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_composite_with_token = [train_attr_x, train_ptag, pages_class, pages_query, train_tag_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"O\", \"PREV\", \"PAGE\", \"NEXT\"]\n",
    "tag2idx = { label:idx for idx,label in enumerate(labels)}\n",
    "idx2tag = { idx:label for idx,label in enumerate(labels)}\n",
    "num_tags = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [np.array([tag2idx.get(l) for l in lab]) for lab in chunks_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs in train_composite_with_token:\n",
    "    print(inputs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.layers.crf import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Dense, Input, Bidirectional, LSTM, Embedding, Masking, Concatenate,\n",
    "                                    AveragePooling2D, MaxPooling2D, Reshape, Attention, GlobalAveragePooling1D\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For custom embedding\n",
    "\n",
    "def get_custom_emb_model(use_crf = True, embedding_size = 32, hidden_size = 300):\n",
    "    ft_shape = (None, 1024)\n",
    "    tag_info_shape = (None, 8)\n",
    "    tag_emb_shape = (None, 256)\n",
    "    ptag_emb_shape = (None, 30)\n",
    "    embbed_output_shape = embedding_size\n",
    "    page_embbed_shape = (-1, embbed_output_shape)\n",
    "    pool_size = (256, 1)\n",
    "    HIDDEN_UNITS = hidden_size\n",
    "    NUM_CLASS = num_tags\n",
    "    \n",
    "    input_ft_embedding = Input(shape=(ft_shape), name=\"input_ft_embeddings\")\n",
    "    input_tag_information = Input(shape=(tag_info_shape), name=\"input_tag_information\")\n",
    "    input_ptag_vector = Input(shape=(ptag_emb_shape), name=\"input_ptag\")\n",
    "    input_class = Input(shape=(tag_emb_shape), name=\"input_class\")\n",
    "    input_query = Input(shape=(tag_emb_shape), name=\"input_query\")\n",
    "\n",
    "    #Embedding layers\n",
    "    ## input_class\n",
    "    class_emb = Embedding(input_dim = class_tokenizer.get_size(), output_dim = embbed_output_shape, input_length=max_page_seq, mask_zero = True)(input_class)\n",
    "    class_emb = AveragePooling2D(pool_size, data_format = 'channels_first')(class_emb)\n",
    "    class_emb = Reshape(page_embbed_shape, name=\"class_emb_out\")(class_emb)\n",
    "    ## input_query\n",
    "    query_emb = Embedding(input_dim = query_tokenizer.get_size(), output_dim = embbed_output_shape, input_length=max_page_seq, mask_zero = True)(input_query)\n",
    "    query_emb = AveragePooling2D(pool_size, data_format = 'channels_first')(query_emb)\n",
    "    query_emb = Reshape(page_embbed_shape, name=\"query_emb_out\")(query_emb)\n",
    "\n",
    "    input_tags = Concatenate()([class_emb, query_emb])\n",
    "    input_tags_FFN = Dense(units = 2 * embbed_output_shape, activation = 'relu')(input_tags)\n",
    "    input_tags_FFN = Dense(units = embbed_output_shape, activation = 'relu', name=\"input_tag_FFN_out\")(input_tags_FFN)\n",
    "\n",
    "\n",
    "    ft_FFN = Dense(units = 512, activation = 'relu', name=\"ft_FFN_01\")(input_ft_embedding)\n",
    "    ft_FFN = Dense(units = 256, activation = 'relu', name=\"ft_FFN_02\")(ft_FFN)\n",
    "    ft_FFN = Dense(units = 128, activation = 'relu', name=\"ft_FFN_out\")(ft_FFN)\n",
    "    \n",
    "    # FFN for ptag\n",
    "#     ptag_FFN = Dense(units = 128, activation = 'relu', name=\"ptag_FFN_01\")(input_ptag_vector)\n",
    "#     ptag_FFN = Dense(units = 64, activation = 'relu', name=\"ptag_FFN_out\")(ptag_FFN)\n",
    "    \n",
    "    merged = Concatenate()([input_tags_FFN, input_ptag_vector, input_tag_information])\n",
    "    model = Bidirectional(LSTM(units = HIDDEN_UNITS//2, return_sequences=True))(merged)\n",
    "#     model = LSTM(units = HIDDEN_UNITS, return_sequences=True)(merged)\n",
    "    if use_crf:\n",
    "        crf=CRF(NUM_CLASS, name='crf_layer')\n",
    "        out =crf(model)\n",
    "    else:\n",
    "        out = Dense(units = NUM_CLASS, activation='softmax')(model)\n",
    "    model = Model([input_ft_embedding, input_ptag_vector, input_class, input_query, input_tag_information], out)\n",
    "    if use_crf:\n",
    "        loss_fn = crf.get_loss\n",
    "    else:\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    return model, loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train/val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_dataSet(data, dataType):\n",
    "    dataset = Dataset.from_generator(lambda: iter(data), dataType)\n",
    "    return dataset\n",
    "def zip_dataSet(data):\n",
    "    data_tuple = tuple(data)\n",
    "    dataset = Dataset.zip(data_tuple)\n",
    "    return dataset\n",
    "def describe_dataset(dataset):\n",
    "    print(train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_splite_to_train_val(composite_x, y, number):\n",
    "    x_train = [ data[:-number] for data in composite_x]\n",
    "    y_train = y[:-number]\n",
    "    x_val = [ data[-number:] for data in composite_x]\n",
    "    y_val = y[-number:]\n",
    "    return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def composite_cut_data(composite_x, y, percent):\n",
    "    number = round(len(y) * percent)\n",
    "    new_composite_x = [ data[:number] for data in composite_x]\n",
    "    new_y = y[:number]\n",
    "\n",
    "    return new_composite_x, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val, y_val = composite_splite_to_train_val(train_composite_with_token, train_y, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_list_to_dataset(x, y, isValidation = False, batch_size = 1):\n",
    "    all_data = None\n",
    "    for data in x:\n",
    "        dataset = list_to_dataSet(data, tf.float32)\n",
    "        if all_data == None:\n",
    "            all_data = dataset\n",
    "        else:\n",
    "            all_data = Dataset.zip((all_data, dataset))\n",
    "    y_ds = list_to_dataSet(y, tf.int32)\n",
    "    final_set = Dataset.zip((all_data, y_ds))\n",
    "    if not isValidation:\n",
    "        final_set = final_set.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    else:\n",
    "        final_set = final_set.batch(batch_size)\n",
    "    return final_set\n",
    "\n",
    "def composite_list_to_dataset(x, batch_size = 1):\n",
    "    all_data = None\n",
    "    for data in x:\n",
    "        dataset = list_to_dataSet(data, tf.float32)\n",
    "        if all_data == None:\n",
    "            all_data = dataset\n",
    "        else:\n",
    "            all_data = Dataset.zip((all_data, dataset))\n",
    "    return all_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data_list_to_dataset(x_train, y_train, isValidation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = data_list_to_dataset(x_val, y_val, isValidation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data by percentage\n",
    "def GenerateData(train_composite_with_token, train_y, percent):\n",
    "    train_composite_with_token, train_y = train_composite_with_token[:len(train_composite_with_token)*percent], train_y[:len(train_y)*percent]\n",
    "    x_train, y_train, x_val, y_val = composite_splite_to_train_val(train_composite_with_token, train_y, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_fn = get_custom_emb_model(use_crf=True, embedding_size = 32, hidden_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate training/val f1-score\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "def calculate_pages_metric(y_true_pages, y_predict_pages):\n",
    "    pages_f1 = []\n",
    "    nexts_f1 = []\n",
    "    avg_f1 = []\n",
    "    for y_true, y_predict in zip(y_true_pages, y_predict_pages):\n",
    "        if len(y_true) == 0:\n",
    "            break\n",
    "        report = classification_report(y_true, y_predict,output_dict=True)\n",
    "#         print(report)\n",
    "        PAGE = report['2']['f1-score']\n",
    "        NEXT = report['3']['f1-score']\n",
    "        pages_f1.append(PAGE)\n",
    "        nexts_f1.append(NEXT)\n",
    "        avg_f1.append((PAGE+NEXT)/2)\n",
    "    return pages_f1, nexts_f1, avg_f1\n",
    "def calculate_page_metric(y_true, y_predict):    \n",
    "    report = classification_report(y_true, y_predict,labels=[0,2,3],output_dict=True)\n",
    "    OTHER = report['0']['f1-score']\n",
    "    PAGE = report['2']['f1-score']\n",
    "    NEXT = report['3']['f1-score']\n",
    "    if 2 in y_true and 3 in y_true:\n",
    "        AVG = (PAGE+NEXT)/2\n",
    "    elif 2 in y_true and 3 not in y_true:\n",
    "        AVG = PAGE\n",
    "    elif 2 not in y_true and 3 in y_true:\n",
    "        AVG = NEXT\n",
    "    else:\n",
    "        AVG = OTHER\n",
    "    return AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test for data predict\n",
    "for (batch_x, batch_y) in train_dataset.take(1):\n",
    "    batch_predict_y = model(batch_x).numpy()\n",
    "    batch_true_y = batch_y.numpy()\n",
    "    print(batch_true_y)\n",
    "    print(calculate_page_metric(batch_true_y[0], batch_predict_y[0]))\n",
    "    print(classification_report(batch_true_y[0], batch_predict_y[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_epoch(epochs, model, optimizer, train_dataset, val_dataset, best_model_method = 'f1-score'):\n",
    "    import time\n",
    "    \n",
    "    epochs = epochs\n",
    "    best_weights = None\n",
    "    best_f1_weights = None\n",
    "    best = np.Inf\n",
    "    best_loss_history = None\n",
    "    best_f1 = 0\n",
    "    best_f1_history = None\n",
    "    avg_epoch_losses = []\n",
    "    avg_epoch_f1s = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x_batch_train, training=True)\n",
    "                loss_value = loss_fn(y_batch_train, logits)\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "            # Log every 50 batches.\n",
    "#             if step % 50 == 0:\n",
    "#                 print(\n",
    "#                     \"Training loss (for one batch) at step %d: %.4f\"\n",
    "#                     % (step, float(loss_value))\n",
    "#                 )\n",
    "#                 print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "\n",
    "\n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        val_losses = []\n",
    "        val_f1s = []\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            val_logits = model(x_batch_val, training=False)\n",
    "            val_loss_value = loss_fn(y_batch_val, val_logits)\n",
    "            val_avg_f1 = calculate_page_metric(y_batch_val.numpy()[0], val_logits.numpy()[0])\n",
    "            val_losses.append(val_loss_value)\n",
    "            val_f1s.append(val_avg_f1)\n",
    "        average_val_loss = np.average(val_losses)\n",
    "        average_val_f1 = np.average(val_f1s)\n",
    "        avg_epoch_losses.append(average_val_loss)\n",
    "        avg_epoch_f1s.append(average_val_f1)\n",
    "        if average_val_loss < best:\n",
    "            best_weights = model.get_weights()\n",
    "            best = average_val_loss\n",
    "            best_loss_history = [val_losses, val_f1s]\n",
    "        if average_val_f1 > best_f1:\n",
    "            best_f1_weights = model.get_weights()\n",
    "            best_f1 = average_val_f1\n",
    "            best_f1_history = [val_losses, val_f1s]\n",
    "        print(\"Validation loss: %.4f\" % (float(average_val_loss),))\n",
    "        print(\"Validation F1: %.4f\" % (float(average_val_f1),))\n",
    "        print(\"Time taken: %.2fs\" % (time.time() - start_time))\n",
    "    print(f\"Best loss: {best}, Best F1: {best_f1}\")\n",
    "    print(f\"Training finish, load best weights. {best_model_method}\")\n",
    "    \n",
    "    if best_model_method == 'loss':\n",
    "        model.set_weights(best_weights)\n",
    "    elif best_model_method == 'f1-score':\n",
    "        model.set_weights(best_f1_weights)\n",
    "    avg_epoch_result = {\"epoch_losses\": avg_epoch_losses, \"epoch_f1s\": avg_epoch_f1s}\n",
    "    return model, avg_epoch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(epochs, model, optimizer, train_dataset, val_dataset):\n",
    "    import time\n",
    "    \n",
    "    epochs = epochs\n",
    "    best_f1_weights = None\n",
    "    best_f1 = 0\n",
    "    best_f1_history = None\n",
    "    best_train = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "#         print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "        start_time = time.time()\n",
    "        train_f1s = []\n",
    "        # Iterate over the batches of the dataset.\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(x_batch_train, training=True)\n",
    "                loss_value = loss_fn(y_batch_train, logits)\n",
    "                train_avg_f1 = calculate_page_metric(y_batch_train.numpy()[0], logits.numpy()[0])\n",
    "                train_f1s.append(train_avg_f1)\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        average_train_f1 = np.average(train_f1s)\n",
    "        \n",
    "        # Run a validation loop at the end of each epoch.\n",
    "        val_losses = []\n",
    "        val_f1s = []\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            val_logits = model(x_batch_val, training=False)\n",
    "            val_loss_value = loss_fn(y_batch_val, val_logits)\n",
    "            val_avg_f1 = calculate_page_metric(y_batch_val.numpy()[0], val_logits.numpy()[0])\n",
    "            val_losses.append(val_loss_value)\n",
    "            val_f1s.append(val_avg_f1)\n",
    "\n",
    "        average_val_f1 = np.average(val_f1s)\n",
    "\n",
    "        if average_val_f1 > best_f1:\n",
    "            best_f1 = average_val_f1\n",
    "            best_train = average_train_f1\n",
    "            \n",
    "    print(f\"Best train f1: {best_train}, Best val f1: {best_f1}\")\n",
    "    \n",
    "    return best_train, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer distribution to corresponding label\n",
    "def label_distribution_to_label(predict_y):\n",
    "    if len(predict_y.shape) != 3:\n",
    "        return predict_y\n",
    "    label_y = list()\n",
    "    for page in predict_y:\n",
    "        tmp = list()\n",
    "        for lab in page:\n",
    "            lab = lab.tolist()\n",
    "            tmp.append(lab.index(max(lab)))\n",
    "        label_y.append(tmp)\n",
    "    return label_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for testing inputs\n",
    "def prepare_for_testing(test_X_raw, test_y_raw): #ft-bert -no chunks\n",
    "    chunks_test_x, chunks_test_y = test_X_raw, test_y_raw\n",
    "    chunks_test_x, chunks_test_y = filter_empty(chunks_test_x, chunks_test_y)\n",
    "    test_token_features, test_tag_features = get_token_tag_features_from_chunks(chunks_test_x)\n",
    "    \n",
    "    test_ptags_vector = get_ptags_vector(test_token_features)\n",
    "    test_ft_emb = pages_to_word_vector_from_keylist('Laser', test_token_features, ['text-full'])\n",
    "    test_tag_info_list = test_tag_features\n",
    "    ## Tokens prepare\n",
    "    test_pages_class, test_pages_query, test_pages_text = prepare_input_ids(test_token_features, max_len)\n",
    "    ## X_test_input\n",
    "    test_composite_input = [test_ft_emb, test_ptags_vector, test_pages_class, test_pages_query, test_tag_info_list]\n",
    "    \n",
    "    ## y_test_input\n",
    "    y_test = [[tag2idx.get(l) for l in lab] for lab in chunks_test_y]\n",
    "    y_test = [[idx2tag.get(lab) for lab in page] for page in y_test]\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    return test_composite_input, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_from_batch(model, x, y, evaluate_labels, multiTask = False):\n",
    "    print(\"Start predicting test data ...\")\n",
    "    test_page_dataset = composite_list_to_dataset(x)\n",
    "    predicted_y = []\n",
    "    for pageIdx, batch_x_test in enumerate(test_page_dataset):\n",
    "        if len(y[pageIdx]) == 0:\n",
    "            batch_predict_y = np.array([])\n",
    "        else:\n",
    "            if multiTask:\n",
    "                batch_predict_y = model(batch_x_test)[0][0].numpy()\n",
    "            else:\n",
    "                batch_predict_y = model(batch_x_test)[0].numpy()\n",
    "#         print(batch_predict_y.shape)\n",
    "        if len(batch_predict_y.shape) != 1:\n",
    "            tmp = list()\n",
    "            for lab in batch_predict_y:\n",
    "                lab = lab.tolist()\n",
    "                tmp.append(lab.index(max(lab)))\n",
    "            batch_predict_y = tmp\n",
    "        predicted_y.append(batch_predict_y)\n",
    "    print(\"Start evaluating test data ...\")\n",
    "    predict_y = np.asarray([[idx2tag.get(lab) for lab in page] for page in predicted_y])\n",
    "#     report = flat_classification_report(y, predict_y, labels=evaluate_labels, digits=3,output_dict=True)\n",
    "    macro_report = page_level_score(predict_y, y)\n",
    "    micro_report = node_level_score(predict_y, y)\n",
    "    print(\"Macro\")\n",
    "    print(macro_report)\n",
    "    print(\"Micro\")\n",
    "    print(micro_report)\n",
    "    return (0.5*(macro_report['page_f1'] + macro_report['next_f1']) + 0.5*(micro_report['page_f1'] + micro_report['next_f1']))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, target = \"all\"):\n",
    "    TEST_MODEL = model\n",
    "#     test_languages = storage.get_all_test_languages()\n",
    "    test_languages = ['en','de','ru','zh','ja','ko']\n",
    "    if target != \"all\":\n",
    "        test_languages = [target]\n",
    "    reports = {}\n",
    "    for language in test_languages:\n",
    "        print(\"Testing language: \", language)\n",
    "        test_urls = [rec['Page URL'] for rec in storage.iter_test_records_by_language(language=language)]\n",
    "        test_X_raw, test_y = storage.get_test_Xy_by_language(language=language)\n",
    "        print(\"pages: {}  domains: {}\".format(len(test_urls), len({get_domain(url) for url in test_urls})))\n",
    "        _test_x, _test_y = prepare_for_testing(test_X_raw, test_y)\n",
    "        score = evaluate_from_batch(TEST_MODEL, _test_x, _test_y, ['PAGE','NEXT'])\n",
    "        print(\"===================================\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_macro_avg(reports):\n",
    "    avg_macro = 0\n",
    "    for lan, report in reports.items():\n",
    "        avg_macro+=report['macro avg']['f1-score']\n",
    "    return avg_macro/len(reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page/Node level evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_level_score(y_pred, y_true):\n",
    "\n",
    "    reports = flat_classification_report(y_true, y_pred, labels=['PAGE', 'NEXT'], digits=3, output_dict = True)\n",
    "\n",
    "    page_prec = reports['PAGE']['precision']\n",
    "    page_rec = reports['PAGE']['recall']\n",
    "    page_f1 = reports['PAGE']['f1-score']\n",
    "    next_prec = reports['NEXT']['precision']\n",
    "    next_rec = reports['NEXT']['recall']\n",
    "    next_f1 = reports['NEXT']['f1-score']\n",
    "    \n",
    "    record = {\"page_prec\": page_prec, \"page_rec\": page_rec, \"page_f1\": page_f1, \"next_prec\": next_prec, \"next_rec\": next_rec, \"next_f1\": next_f1}\n",
    "    return record\n",
    "\n",
    "def page_level_score(y_pred, y_true):\n",
    "    page_prec = 0\n",
    "    page_rec = 0\n",
    "    page_f1 = 0\n",
    "    next_prec = 0\n",
    "    next_rec = 0\n",
    "    next_f1 = 0\n",
    "    macro_f1 = 0\n",
    "    size = 0\n",
    "    for idx, (page_pred, page_true) in enumerate(zip(y_pred, y_true)):\n",
    "        \n",
    "        if 'NEXT' not in page_true and 'PAGE' not in page_true and 'PREV' not in page_true:\n",
    "#             print(\"Continue at \",idx)\n",
    "            continue\n",
    "        else:\n",
    "            size += 1\n",
    "        reports = classification_report(page_true, page_pred, labels=['PAGE', 'NEXT'], digits=3, output_dict = True)\n",
    "#         print(reports)\n",
    "        page_prec += reports['PAGE']['precision']\n",
    "        page_rec += reports['PAGE']['recall']\n",
    "        page_f1 += reports['PAGE']['f1-score']\n",
    "        next_prec += reports['NEXT']['precision']\n",
    "        next_rec += reports['NEXT']['recall']\n",
    "        next_f1 += reports['NEXT']['f1-score']\n",
    "    record = {\"page_prec\": page_prec/size, \"page_rec\": page_rec/size, \"page_f1\": page_f1/size, \"next_prec\": next_prec/size, \"next_rec\": next_rec/size, \"next_f1\": next_f1/size}\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_model(model, target='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_records = []\n",
    "for percent in [0.2, 0.4, 0.6, 0.8, 1]:\n",
    "    for Iteration in range(5):\n",
    "        new_composite_x, new_y = composite_cut_data(train_composite_with_token, train_y, percent)\n",
    "        train_case = len(new_y)\n",
    "        test_case = round(train_case * 0.2)\n",
    "        print(f\"Train case: {train_case}, Test case: {test_case}\")\n",
    "        x_train, y_train, _, _ = composite_splite_to_train_val(new_composite_x, new_y, test_case)\n",
    "        _, _, x_val, y_val = composite_splite_to_train_val(train_composite_with_token, train_y, 20)\n",
    "        train_dataset = data_list_to_dataset(x_train, y_train, isValidation=False)\n",
    "        val_dataset = data_list_to_dataset(x_val, y_val, isValidation=True)\n",
    "        model, loss_fn = get_custom_emb_model(use_crf=True, embedding_size = 32, hidden_size = 300)\n",
    "        best_train, best_f1 = learning_curve(15, model, optimizer, train_dataset, val_dataset)\n",
    "        Learning_records.append({\"Pages\": train_case, \"Iteration\": Iteration, \"best_train\": best_train, \"best_test\": best_f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Learning_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_train_f1s = []\n",
    "lc_val_f1s = []\n",
    "for train_pages in [33, 66, 98, 131, 164]:\n",
    "    tmp_train = []\n",
    "    tmp_val = []\n",
    "    for record in Learning_records:\n",
    "        if record['Pages'] == train_pages:\n",
    "            tmp_train.append(record['best_train'])\n",
    "            tmp_val.append(record['best_test'])\n",
    "    lc_train_f1s.append(tmp_train)\n",
    "    lc_val_f1s.append(tmp_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_train_f1s = [[0.819,0.679,0.705,0.793,0.774],[0.966,0.377,0.935,0.934,0.912],[0.926,0.938,0.965,0.951,0.925],[0.98,0.944,0.958,0.964,0.96],[0.965,0.937,0.942,0.939,0.96]]\n",
    "lc_val_f1s   = [[0.628,0.695,0.636,0.638,0.67],[0.804,0.3,0.78,0.789,0.762],[0.774,0.746,0.806,0.778,0.767],[0.829,0.829,0.789,0.802,0.791],[0.806,0.809,0.804,0.788,0.809]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_pd = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, page_sample in zip(lc_train_f1s, [33, 66, 98, 131, 164]):\n",
    "    train_type = 'train'\n",
    "    for idx, score in enumerate(data):\n",
    "        record = {\"train_type\": train_type, \"sample_size\": page_sample, \"iteration\": idx, \"macro F1\": score}\n",
    "        learning_curve_pd = learning_curve_pd.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, page_sample in zip(lc_val_f1s, [33, 66, 98, 131, 164]):\n",
    "    train_type = 'val'\n",
    "    for idx, score in enumerate(data):\n",
    "        record = {\"train_type\": train_type, \"sample_size\": page_sample, \"iteration\": idx, \"macro F1\": score}\n",
    "        learning_curve_pd = learning_curve_pd.append(record, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_train_means = np.mean(lc_train_f1s, axis = 1)\n",
    "lc_val_means = np.mean(lc_val_f1s, axis = 1)\n",
    "lc_train_std = np.std(lc_train_f1s, axis = 1)\n",
    "lc_val_std = np.std(lc_val_f1s, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.array([33, 66, 98, 131, 164])\n",
    "_, axes = plt.subplots(1,3,figsize=(20, 5))\n",
    "axes[0].set_xlabel(\"Training pages\")\n",
    "axes[0].set_ylabel(\"Macro F1 Score\")\n",
    "\n",
    "# Plot learning curve\n",
    "axes[0].grid()\n",
    "axes[0].fill_between(train_sizes, lc_train_means - lc_train_std,\n",
    "                     lc_train_means + lc_train_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "axes[0].fill_between(train_sizes, lc_val_means - lc_val_std,\n",
    "                     lc_val_means + lc_val_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "axes[0].plot(train_sizes, lc_train_means, 'x-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "axes[0].plot(train_sizes, lc_val_means, 'x-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "axes[0].legend(loc=\"best\")\n",
    "axes[0].set_title(\"Macro F1 on EN dev --> EN test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Vector Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_EXP_RECORDS = []\n",
    "for iteration in range(5):\n",
    "    print(\"Iteration start \",iteration)\n",
    "    model, loss_fn = get_custom_emb_model(use_crf=True, embedding_size = 32, hidden_size = 300)\n",
    "    model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "    score = evaluate_model(model, target='en')\n",
    "    TAG_EXP_RECORDS.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = evaluate_model(model, target = 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation Tag Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTAG_ABLA_EXP_RECORDS = []\n",
    "for iteration in range(3):\n",
    "    print(\"Iteration start \",iteration)\n",
    "    model, loss_fn = get_ablation_ptag_model(use_crf=True)\n",
    "    model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "    reports = evaluate_model(model)\n",
    "    macro_avg = calculate_macro_avg(reports)\n",
    "    print(f\"Iter: {iteration}, macro f1: {macro_avg}\")\n",
    "    record = {\"iter\": iteration, \"macro_avg\": macro_avg}\n",
    "    PTAG_ABLA_EXP_RECORDS.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PTAG_ABLA_EXP_RECORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUE_EXP_RECORDS = []\n",
    "for iteration in range(2):\n",
    "    print(\"Iteration start \",iteration)\n",
    "    model, loss_fn = get_ablation_model_hl(use_crf=True)\n",
    "    model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "    score = evaluate_model(model, target='en')\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUE_EXP_RECORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMB Exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_EXP_RECORDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for EMB_SIZE in [16,32,64,128]:\n",
    "    for iteration in range(5):\n",
    "        print(\"Iteration start \",iteration)\n",
    "        model, loss_fn = get_custom_emb_model(use_crf=True, embedding_size = EMB_SIZE, hidden_size = 300)\n",
    "        model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "        print(\"best: \",best)\n",
    "        reports = evaluate_model(model)\n",
    "        macro_avg = calculate_macro_avg(reports)\n",
    "        print(f\"Iter: {iteration}, macro f1: {macro_avg}\")\n",
    "        record = {\"EMB_SIZE\": EMB_SIZE, \"iter\": iteration, \"macro_avg\": macro_avg}\n",
    "        EMB_EXP_RECORDS.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_EXP_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(EMB_EXP_RECORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Hidden Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD_SIZE_RECORDS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NUERON_SIZE in [400, 500]:\n",
    "    for iteration in range(5):\n",
    "        print(\"Iteration start \",iteration)\n",
    "        model, loss_fn = get_custom_emb_model(use_crf=True, embedding_size = 32, hidden_size=NUERON_SIZE)\n",
    "        model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "        reports = evaluate_model(model)\n",
    "        macro_avg = calculate_macro_avg(reports)\n",
    "        print(f\"Iter: {iteration}, macro f1: {macro_avg}\")\n",
    "        record = {\"NUERON_SIZE\": NUERON_SIZE, \"iter\": iteration, \"macro_avg\": macro_avg}\n",
    "        HD_SIZE_RECORDS.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HD_SIZE_RECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(HD_SIZE_RECORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attr Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ablation_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(3):\n",
    "    for attrReq in ['class','query']:\n",
    "        print(\"Iteration start \",iteration)\n",
    "        print(\"Attr: \",attrReq)\n",
    "        model, loss_fn = get_ablation_model(attrReq=attrReq)\n",
    "        model, avg_epoch_result = train_on_epoch(25, model, optimizer, train_dataset, val_dataset)\n",
    "        reports = evaluate_model(model)\n",
    "        macro_avg = calculate_macro_avg(reports)\n",
    "        print(f\"Iter: {iteration}, attrReq: {attrReq}, macro f1: {macro_avg}\")\n",
    "        record = {\"iter\": iteration, \"macro_avg\": macro_avg, \"attrReq\": attrReq}\n",
    "        Ablation_records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ablation_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(4):\n",
    "    print(\"Iteration start \",iteration)\n",
    "    model, loss_fn = get_custom_emb_model()\n",
    "    model, avg_epoch_result = train_on_epoch(15, model, optimizer, train_dataset, val_dataset)\n",
    "    score = evaluate_model(model, target = 'en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrData = pd.read_csv('AttrEmbData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmData = pd.read_csv('lstmData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrData = attrData.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"EMB_SIZE\", y=\"macro_avg\", data=attrData, showfliers=False)\n",
    "ax.set_xlabel(\"Attribute Embedding Size\")\n",
    "ax.set_ylabel(\"Macro F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.savefig(\"AttributeEmbeddingSize.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"NUERON_SIZE\", y=\"macro_avg\", data=lstmData, showfliers=False)\n",
    "ax.set_xlabel(\"LSTM Hidden Size\")\n",
    "ax.set_ylabel(\"Macro F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "fig.savefig(\"LSTMHiddenSize.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enDev_macro = pd.read_csv('en_dev_macro_sns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enDev_macro.loc[enDev_macro['Method'] == 'CRFSuite', 'Method'] = 'Autopager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"Label\", y=\"F1\", hue=\"Method\",\n",
    "                 data=enDev_macro, palette=\"Set3\")\n",
    "ax.set_title(\"Macro F1 on En Dev --> En Test\")\n",
    "ax.set_ylim(0.5,1)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Macro F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enDev_micro = pd.read_csv('en_dev_micro_sns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enDev_micro.loc[enDev_micro['Method'] == 'CRFSuite', 'Method'] = 'Autopager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"Label\", y=\"F1\", hue=\"Method\",\n",
    "                 data=enDev_micro, palette=\"Set3\")\n",
    "ax.set_title(\"Micro F1 on En Dev --> En Test\")\n",
    "ax.set_ylim(0.5,1)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Micro F1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
